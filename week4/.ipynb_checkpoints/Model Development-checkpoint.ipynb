{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "\n",
    "## What is a Model?\n",
    "\n",
    "* A model can be thought as a mathematical equation used to predict a value given one or more other values.\n",
    "* Relating one or more inde pendent variables to dependent variables.\n",
    "\n",
    "### Example\n",
    "\n",
    "![model_definition](./model.svg)\n",
    "\n",
    "* Usually the more relevant data you have the more accuarate your model is.\n",
    "\n",
    "![model_accuarate](./model_accuarate.svg)\n",
    "\n",
    "* To understand why more data is important consider the following sitation.\n",
    "* Pink cars sell for singinficantly less.\n",
    "\n",
    "![model_diff](./model_diff.svg)\n",
    "\n",
    "# Linear Regression \n",
    "\n",
    "* Linear regression will refer to one independent variable to make a prediction.\n",
    "* Multiple linear regression will refer to multiple independent-variables to make a prediction.\n",
    "\n",
    "![linear regresion](./liearRegression.svg)\n",
    "\n",
    "# Simple Linear Regression\n",
    "\n",
    "Simple linear regression or **SLR** is method to help us understand the reation between two variables. \n",
    "1. The predictor (independet) variable $X$\n",
    "2. The target (dependent) variable $y$\n",
    "### $$y={ b }_{ 0 }+{ b }_{ 1 }x$$\n",
    "* ${ b }_{ 0 }$:The Intercept\n",
    "* ${ b }_{ 1 }$:The Slope\n",
    "\n",
    "# Simple Linear Regression:Prediction\n",
    "\n",
    "* If we assume there is a linear relationship between these variables, it's is possible to use this relationship to formulate a model to determine the price of the car.\n",
    "$$y=38423-821x$$\n",
    "![simplelinearregression](./modelevaluatedSLR.svg)\n",
    "$$y=38423-821(20)$$\n",
    "$$y=22000$$\n",
    "\n",
    "\n",
    "# Simple Linear Regression: FIT\n",
    "\n",
    "* In order to determine the line, we take data points from our dataset marked in red and then we use these training points to fit our model. The result of the training points are the parameters.\n",
    "\n",
    "![fitregression](./fitmodelprocess.svg)\n",
    "\n",
    "* We usually store the data points into dataframe or numpy arrays\n",
    "\n",
    "$$x=\\begin{bmatrix} 0 \\\\ 20 \\\\ 40 \\end{bmatrix}\\quad y=\\begin{bmatrix} 38243 \\\\ 22003 \\\\ 5583 \\end{bmatrix}$$\n",
    "\n",
    "* The value we would like to predict i called target that we store in the array $Y$\n",
    "\n",
    "* We store the independet variable in the dataframe or array $X$\n",
    "\n",
    "\n",
    "# Simple Linear Regression: NOISE\n",
    "\n",
    "* In many cases, many factors influence how much people pay for a car. For example make or how old the car is. In this model, this uncertainty is taken into a account by assuming a small random value is added to the point on the line. This is called noise. \n",
    "\n",
    "![noiseNormal](./noise.svg)\n",
    "\n",
    "* Vertical axis shows the value added and the horizontal axis illustrates the probability that the value will be added\n",
    "\n",
    "# Simple Linear Regression Steps.\n",
    "\n",
    "1. We have a set of training points.\n",
    "2. We use these training points to fit or train the model and get parameters\n",
    "3. we then use these parameters in the model.\n",
    "4. We get the model \n",
    "5. we can use these model to predict values that we haven't seen.\n",
    "\n",
    "### Example:\n",
    "\n",
    "* We have no car with 20 highway miles per gallon, so we can use our model to make a prediction for the price of the car. \"Don't forget that model are not always correct\"\n",
    "\n",
    "* If the linear assumption is correct this error is due to the noise.\n",
    "\n",
    "![linear regression process](./linearRegProc2.svg)\n",
    "\n",
    "# Fitting a Simple Linear Model Stimator\n",
    "\n",
    "* X: Predictor variable.\n",
    "* Y: Target Variable.\n",
    "    1. Import Linear-Model from scikit-learn.\n",
    "     ```python\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "     ```\n",
    "    2. Create a linear regression object using the constructor.\n",
    "        ```python\n",
    "        lm = LinearRegression()\n",
    "        ```\n",
    "    3. We define the predictor variable and target variable.\n",
    "        ```python\n",
    "            X=df[[\"highway-mpg\"]]\n",
    "            Y=df[[\"price\"]]\n",
    "        ```\n",
    "    4. Then we use lm.fit(X,Y) to fit the model, and find the parameters ${ b }_{ 0 }$ and ${ b }_{ 1 }$\n",
    "    5. We can obtain a prediction.\n",
    "        ```python\n",
    "            Yhat = lm.predict(X)\n",
    "        ```\n",
    "    6. We can view the intercept ${ b }_{ 0 }$ \n",
    "        ```python\n",
    "            lm.intercept\n",
    "        ```\n",
    "    7. We can also view the slope ${ b }_{ 1 }$\n",
    "        ```python\n",
    "            lm.coef\n",
    "        ```\n",
    "    8. The relationship between price and **HIGHWAY MPG\"\" \n",
    "        $$price = 38423.31 - 821.73*highway-mpg $$\n",
    "\n",
    "# Multiple Linear Regression (MLR)\n",
    "\n",
    "* This method is used to explain the relationship between:\n",
    "    * One continues target(Y) variable.\n",
    "    * Two or more predictor (X) variables.\n",
    "    $$\\widehat { Y } ={ b }_{ 0 }+{ b }_{ 1 }{ x }_{ 1 }+{ b }_{ 2 }{ x }_{ 2 }+{ b }_{ 3 }{ x }_{ 3 }+{ b }_{ 4 }{ x }_{ 4 }$$\n",
    "    \n",
    "    * ${ b }_{ 0 }$: intercept(X=0)\n",
    "    * ${ b }_{ 1 }$: The coefficient or parameter of ${ x }_{ 1 }$\n",
    "    * ${ b }_{ 2 }$: The coefficient or parameter of ${ x }_{ 2 }$ and so on\n",
    "\n",
    "### Example\n",
    "In this example of multivarible equation can be visualized on a 2d plate  $\\hat { y } =1+2{ x }_{ 1 }+3{ x }_{ 2 }$ the variables ${ x }_{ 1 }$ and ${ x }_{ 2 }$ \n",
    "\n",
    "\n",
    "![multiple3d](./multime3d.svg)\n",
    "\n",
    "# Fitting a Multiple Linear Model Stimator\n",
    "\n",
    "1. We can extract the 4 predictor and store them in the variable z.\n",
    "    ```python\n",
    "       z = df[[\"horsepower\", \"curb-weight\", \"engine-size\", \"highway-mpg\"]]\n",
    "    ```\n",
    "2. Then train the model as before.\n",
    "    ```python\n",
    "        lm.fit(z,df[[\"price\"]])\n",
    "    ```\n",
    "3. we can also obtain a prediction.\n",
    "    ```python\n",
    "        lm.predict(z)\n",
    "    ```\n",
    "    \n",
    "# Multiple-Estimated Linear Model.\n",
    "\n",
    "1. Find the intercept (${ b }_{ 0 }$).\n",
    "    ```python\n",
    "    -15678.14262\n",
    "    ```\n",
    "2. Find the coeficients (${ b }_{ 0 }$,${ b }_{ 1 }$,${ b }_{ 2 }$,${ b }_{ 3 }$,${ b }_{ 4 }$).\n",
    "     ```python\n",
    "        lm.coef_\n",
    "        array[52.2, 4.61, 81.5, 33.53] not the exact values\n",
    "    ```\n",
    "3. The estimated linear model.\n",
    "    \n",
    "    $$price=-15678.74+52.66*horsepower+4.70*curb-weigh+81.96*enginesize+33.58*highwaympg$$\n",
    "   \n",
    "\n",
    "\n",
    "# Regression Plot.\n",
    "\n",
    "### why use regression plot?\n",
    "\n",
    "* it gives us a good estimate of:\n",
    "    1. The relationship between two variables.\n",
    "    2. The strength of the correlation,\n",
    "    3. The direction of the relationship (Positive or negative).\n",
    "\n",
    "Regression Plot shows us a combination of:\n",
    "\n",
    "* The scatterplot: Where each point represents a different $y$\n",
    "* The fitted linear regression line ($\\hat { y } $)\n",
    "\n",
    "![regressionplot](./plotReg.svg)\n",
    "\n",
    "\n",
    "# Regression Plot: Python.\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "```python\n",
    "sns.regplot(x=\"highway-mpg\", y='price', data=df)\n",
    "plt.ylim(0,)\n",
    "```\n",
    "\n",
    "# Residual Plot.\n",
    "\n",
    "The residual plot represent the error between the actual value, examining the predicted value and actual value we see a difference. We obtain that value by subtracting the predicted value and the actual target value. We then plot that value on the vertical axis with the dependent variable as the horizontal axis. We expect to see the resulsts to have zero mean, distributed evenly around the **x** axis with similar variance.\n",
    "\n",
    "![residualPlot](./residualPlot.svg)\n",
    "\n",
    "# Residual Plot: Case 1.\n",
    "\n",
    "![residualplotcase1](./residualplotcase1.png)\n",
    "\n",
    "\n",
    "* Randomly spread out around x-axis then a linear model is appropiate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
